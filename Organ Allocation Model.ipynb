{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, States to explore: 1\n",
      "Pruned to 20 states.\n",
      "Delta: 7.977777777777778\n",
      "Iteration 2, States to explore: 20\n",
      "Pruned to 111 states.\n",
      "Delta: 7.977777777777778\n",
      "Iteration 3, States to explore: 111\n",
      "Pruned to 202 states.\n",
      "Delta: 7.977777777777778\n",
      "Iteration 4, States to explore: 202\n",
      "Pruned to 74 states.\n",
      "Delta: 100.0\n",
      "Iteration 5, States to explore: 74\n",
      "Pruned to 0 states.\n",
      "Delta: 0\n",
      "(1, 'A')\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-100, 1, 0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "class SequentialOrganAllocationMDP:\n",
    "    def __init__(self, initial_state, available_organs):\n",
    "        \"\"\"\n",
    "        Initialize the sequential MDP for organ allocation.\n",
    "\n",
    "        Parameters:\n",
    "        - initial_state: List of dictionaries representing waitlist candidates.\n",
    "        - available_organs: Dictionary with available organs by blood type.\n",
    "        \"\"\"\n",
    "        self.initial_state = (\n",
    "            tuple((r['id'], r['age'], r['MELD'], r['blood_type'], r['allocated']) for r in initial_state),\n",
    "            tuple(available_organs.items())\n",
    "        )\n",
    "        self.value_table = {self.initial_state: 0}  # Value function initialized for the initial state\n",
    "        self.policy = {self.initial_state: None}  # Policy initialized for the initial state\n",
    "        self.deltas = []  # To store deltas over iterations\n",
    "\n",
    "    def calculate_reward(self, recipient):\n",
    "        \"\"\"\n",
    "        Calculate reward for successfully allocating an organ.\n",
    "\n",
    "        Parameters:\n",
    "        - recipient: Tuple representing the recipient receiving the organ.\n",
    "\n",
    "        Returns:\n",
    "        - Reward value based on MELD score and age.\n",
    "        \"\"\"\n",
    "        _, age, meld, _, _ = recipient\n",
    "        return 10 + (1 / (1 + max(meld,0))) * 10 - (age * 0.1) #this is giving inf rewards sometimes\n",
    "\n",
    "    def generate_next_state(self, state, action):\n",
    "        \"\"\"\n",
    "        Generate the next state based on the current state and action.\n",
    "\n",
    "        Parameters:\n",
    "        - state: Tuple (recipients, available_organs).\n",
    "        - action: Tuple (recipient_id, organ_type).\n",
    "\n",
    "        Returns:\n",
    "        - next_state: Updated state after taking the action.\n",
    "        - reward: Associated reward for the action.\n",
    "        \"\"\"\n",
    "        recipients, available_organs = state\n",
    "        recipients = list(recipients)\n",
    "        available_organs = dict(available_organs)\n",
    "\n",
    "        if action is None:\n",
    "            return (tuple(recipients), tuple(available_organs.items())), 0\n",
    "\n",
    "        recipient_id, organ_type = action\n",
    "        recipient_idx = next((i for i, r in enumerate(recipients) if r[0] == recipient_id), None)\n",
    "\n",
    "        if recipient_idx is not None and available_organs[organ_type] > 0:\n",
    "            if random.random() < 0.8:  # 90% success\n",
    "                recipient = recipients[recipient_idx]\n",
    "                recipients[recipient_idx] = (recipient[0], recipient[1], recipient[2], recipient[3], 1)\n",
    "                available_organs[organ_type] -= 1\n",
    "                reward = self.calculate_reward(recipient)\n",
    "                return (tuple(recipients), tuple(available_organs.items())), reward\n",
    "            else:  # 10% failure (recipient dies, organ is removed)\n",
    "                recipient = recipients.pop(recipient_idx)\n",
    "                available_organs[organ_type] -= 1\n",
    "                reward = -100  # Large penalty for death\n",
    "                return (tuple(recipients), tuple(available_organs.items())), reward\n",
    "\n",
    "        return (tuple(recipients), tuple(available_organs.items())), 0\n",
    "    '''\n",
    "    def value_iteration(self, gamma=0.9, epsilon=0.01):\n",
    "        \"\"\"\n",
    "        Perform value iteration for all reachable states starting from the initial state.\n",
    "\n",
    "        Parameters:\n",
    "        - gamma: Discount factor (default 0.9).\n",
    "        - epsilon: Convergence threshold (default 0.01).\n",
    "        \"\"\"\n",
    "        states_to_explore = deque([self.initial_state])\n",
    "        self.deltas = []  # Reset deltas at the start of value iteration\n",
    "        iter = 0\n",
    "        while True:  # Outer loop for global convergence\n",
    "            delta = 0  # Track the largest change in value across all states\n",
    "            iter += 1\n",
    "            print(f\"Iteration: {iter}\")\n",
    "            new_states_to_explore = deque()  # To track states added during this iteration\n",
    "\n",
    "            \n",
    "            while states_to_explore:  # Inner loop for processing current state\n",
    "                current_state = states_to_explore.popleft()\n",
    "                old_value = self.value_table[current_state]\n",
    "                max_value = float('-inf')\n",
    "                best_action = None\n",
    "                no_valid_actions = True\n",
    "\n",
    "                recipients, available_organs = current_state\n",
    "                available_organs = dict(available_organs)\n",
    "                for recipient in recipients:\n",
    "                    if recipient[4] == 0:  # Not yet allocated\n",
    "                        for organ_type in available_organs.keys():\n",
    "                            if available_organs[organ_type] > 0:\n",
    "                                action = (recipient[0], organ_type)\n",
    "                                next_state, reward = self.generate_next_state(current_state, action)\n",
    "                                value = reward + gamma * self.value_table.get(next_state, 0)\n",
    "                                no_valid_actions = False\n",
    "                                if np.abs(value) == float('inf') or np.abs(value) > 1e6:\n",
    "                                    print(f\"Large Reward: {reward}\")\n",
    "                                    print(f\"Curr state: {current_state}, Action: {action}, Next state: {next_state}\")\n",
    "\n",
    "\n",
    "\n",
    "                                if value > max_value:\n",
    "                                    max_value = value\n",
    "                                    best_action = action\n",
    "\n",
    "                                if next_state not in self.value_table:\n",
    "                                    self.value_table[next_state] = 0\n",
    "                                    self.policy[next_state] = None\n",
    "                                    new_states_to_explore.append(next_state)\n",
    "                if no_valid_actions:\n",
    "                    continue\n",
    "                self.value_table[current_state] = max_value\n",
    "                #print(max_value)\n",
    "                self.policy[current_state] = best_action\n",
    "                delta = max(delta, abs(old_value - max_value))\n",
    "                #delta = abs(old_value - max_value)\n",
    "            print(f\"Delta: delta\")\n",
    "            self.deltas.append(delta)  # Append delta for this iteration\n",
    "            states_to_explore = new_states_to_explore  # Add newly discovered states\n",
    "            #print(f\"New states to explore: {len(new_states_to_explore)}\")\n",
    "            print(f\"Total of states to explore: {len(states_to_explore)}\")\n",
    "\n",
    "            if delta < epsilon and not states_to_explore:\n",
    "                break  # Stop when values converge and no new states to explore\n",
    "    '''\n",
    "    def value_iteration(self, gamma=0.9, epsilon=0.01, max_states=10000):\n",
    "        \"\"\"\n",
    "        Perform value iteration with pruning.\n",
    "        \n",
    "        Parameters:\n",
    "        - gamma: Discount factor (default 0.9).\n",
    "        - epsilon: Convergence threshold (default 0.01).\n",
    "        - max_states: Maximum number of states to retain in the queue during pruning.\n",
    "        \"\"\"\n",
    "        states_to_explore = deque([self.initial_state])\n",
    "        visited_states = set()  # Track visited states\n",
    "        self.deltas = []  # Reset deltas at the start of value iteration\n",
    "        iteration_count = 0\n",
    "\n",
    "        while True:\n",
    "            iteration_count += 1\n",
    "            delta = 0\n",
    "            new_states_to_explore = []\n",
    "\n",
    "            print(f\"Iteration {iteration_count}, States to explore: {len(states_to_explore)}\")\n",
    "\n",
    "            while states_to_explore:\n",
    "                current_state = states_to_explore.popleft()\n",
    "\n",
    "                # Skip already visited states\n",
    "                if current_state in visited_states:\n",
    "                    continue\n",
    "\n",
    "                visited_states.add(current_state)\n",
    "                old_value = self.value_table[current_state]\n",
    "                max_value = float('-inf')\n",
    "                best_action = None\n",
    "                no_valid_actions = True\n",
    "\n",
    "                recipients, available_organs = current_state\n",
    "                available_organs = dict(available_organs)\n",
    "\n",
    "                for recipient in recipients:\n",
    "                    if recipient[4] == 0:  # Not yet allocated\n",
    "                        for organ_type in available_organs.keys():\n",
    "                            if available_organs[organ_type] > 0:\n",
    "                                no_valid_actions = False\n",
    "                                action = (recipient[0], organ_type)\n",
    "                                next_state, reward = self.generate_next_state(current_state, action)\n",
    "                                value = reward + gamma * self.value_table.get(next_state, 0)\n",
    "\n",
    "                                if value > max_value:\n",
    "                                    max_value = value\n",
    "                                    best_action = action\n",
    "\n",
    "                                if next_state not in self.value_table:\n",
    "                                    self.value_table[next_state] = 0\n",
    "                                    self.policy[next_state] = None\n",
    "                                    new_states_to_explore.append((next_state, abs(old_value - max_value)))\n",
    "                if no_valid_actions:\n",
    "                    continue\n",
    "                self.value_table[current_state] = max_value\n",
    "                self.policy[current_state] = best_action\n",
    "                delta = max(delta, abs(old_value - max_value))\n",
    "\n",
    "            # Prune new states\n",
    "            new_states_to_explore.sort(key=lambda x: x[1], reverse=True)  # Sort by delta (value change)\n",
    "            new_states_to_explore = [state for state, _ in new_states_to_explore[:max_states]]\n",
    "\n",
    "            print(f\"Pruned to {len(new_states_to_explore)} states.\")\n",
    "\n",
    "            states_to_explore = deque(new_states_to_explore)\n",
    "            self.deltas.append(delta)\n",
    "            print(f\"Delta: {delta}\")\n",
    "\n",
    "            if delta < epsilon and not states_to_explore:\n",
    "                break\n",
    "\n",
    "    def get_deltas(self):\n",
    "        \"\"\"\n",
    "        Retrieve the deltas recorded during value iteration.\n",
    "\n",
    "        Returns:\n",
    "        - List of delta values for each iteration.\n",
    "        \"\"\"\n",
    "        return self.deltas #To use for plotting later\n",
    "\n",
    "    def simulate_with_policy(self, steps=10):\n",
    "        \"\"\"\n",
    "        Simulate the allocation process using the computed policy.\n",
    "\n",
    "        Parameters:\n",
    "        - steps: Number of allocation steps to simulate (default 10).\n",
    "\n",
    "        Returns:\n",
    "        - Total reward, total deaths, total allocations.\n",
    "        \"\"\"\n",
    "        current_state = self.initial_state\n",
    "        total_reward = 0\n",
    "        total_deaths = 0\n",
    "        total_allocations = 0\n",
    "\n",
    "        for _ in range(steps):\n",
    "            action = self.policy.get(current_state, None)\n",
    "            print(action)\n",
    "            if action is None:\n",
    "                break\n",
    "\n",
    "            next_state, reward = self.generate_next_state(current_state, action)\n",
    "\n",
    "            if reward == -100:  # Death penalty\n",
    "                total_deaths += 1\n",
    "            elif reward > 0:  # Successful allocation\n",
    "                total_allocations += 1\n",
    "\n",
    "            total_reward += reward\n",
    "            current_state = next_state\n",
    "\n",
    "        return total_reward, total_deaths, total_allocations\n",
    "\n",
    "\n",
    "# Reinitialize the example with a reduced state space for debugging\n",
    "df = pd.read_csv('waitlist_patients.csv')\n",
    "\n",
    "initial_state = df.apply(\n",
    "    lambda row: {\n",
    "        'id': row.name + 1,  # Generate an 'id' starting from 1\n",
    "        'age': row['RECIPIENT_AGE'],  # Replace with the actual age column if available\n",
    "        'MELD': row['INIT_MELD_PELD_LAB_SCORE'],\n",
    "        'blood_type': row['RECIPIENT_BLOOD_TYPE'],\n",
    "        'allocated': 0  # Default value\n",
    "    }, axis=1\n",
    ").tolist()\n",
    "available_organs = {'A': 6, 'A1': 6, 'A1B': 0, 'A2': 0, 'A2B': 2, 'AB': 0, 'B': 3, 'O': 27, 'AB': 0}\n",
    "\n",
    "initial_state = [\n",
    "    {'id': i, 'age': random.randint(20, 70), 'MELD': random.randint(10, 40), 'blood_type': random.choice(['A', 'B', 'O', 'AB']), 'allocated': 0}\n",
    "    for i in range(1, 6)\n",
    "]\n",
    "available_organs = {'A': 1, 'B': 1, 'O': 1, 'AB': 1}\n",
    "\n",
    "# Initialize and execute the MDP\n",
    "mdp_model = SequentialOrganAllocationMDP(initial_state, available_organs)\n",
    "mdp_model.value_iteration()\n",
    "deltas = mdp_model.get_deltas()\n",
    "total_reward, total_deaths, total_allocations = mdp_model.simulate_with_policy(steps=20)\n",
    "\n",
    "\n",
    "total_reward, total_deaths, total_allocations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RECIPIENT_BLOOD_TYPE\n",
       "O     27\n",
       "A     20\n",
       "B     11\n",
       "AB     5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RECIPIENT_BLOOD_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ORGAN_TRANSPLANT_ID', 'WAITLIST_ID', 'RECIPIENT_ID', 'DONOR_ID',\n",
       "       'RECIPIENT_GENDER', 'RECIPIENT_AGE', 'DONOR_AGE', 'INIT_MELD_OR_PELD',\n",
       "       'INIT_MELD_PELD_LAB_SCORE', 'FINAL_MELD_OR_PELD',\n",
       "       'FINAL_MELD_PELD_LAB_SCORE', 'FUNCTIONAL_STATUS_AT_REGISTRATION',\n",
       "       'FUNCTIONAL_STATUS_AT_FOLLOW_UP', 'FUNCTIONAL_STATUS_AT_TRANSPLANT',\n",
       "       'STATUS_AT_REGISTRATION', 'DIAGNOSIS', 'PATIENT_SURVIVAL_TIME',\n",
       "       'DAYS_ON_WAITLIST', 'REJECTED_WITHIN_YEAR', 'TRANSPLANT_DATE',\n",
       "       'DONOR_LIVER_QUALITY', 'RECIPIENT_BLOOD_TYPE', 'DONOR_BLOOD_TYPE',\n",
       "       'DONOR_RECIPIENT_BLOOD_LEVEL', 'GRAFT_FUNCTIONING', 'GRAFT_LIFESPAN',\n",
       "       'DONOR_ADMISSION_DATE', 'DONOR_TYPE', 'ORGAN_RECOVERY_DATE',\n",
       "       'WAITLIST_REGISTRATION_DATE', 'END_DATE', 'REASON_REMOVED_WAITLIST',\n",
       "       'RECIPIENT_STATUS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organs = pd.read_csv('available_organs.csv')\n",
    "valid = organs[organs['INIT_MELD_OR_PELD'] == 'MELD']\n",
    "\n",
    "valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('waitlist_patients.csv')\n",
    "\n",
    "initial_state = df.apply(\n",
    "    lambda row: {\n",
    "        'id': row.name + 1,  # Generate an 'id' starting from 1\n",
    "        'age': row['RECIPIENT_AGE'],  # Replace with the actual age column if available\n",
    "        'MELD': row['INIT_MELD_PELD_LAB_SCORE'],\n",
    "        'blood_type': row['RECIPIENT_BLOOD_TYPE'],\n",
    "        'allocated': 0  # Default value\n",
    "    }, axis=1\n",
    ").tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
