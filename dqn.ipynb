{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "all_transplants, _ = read_organ_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_directory = 'data'\n",
    "\n",
    "for filename in os.listdir(data_directory):\n",
    "    if filename.endswith('waitlist.csv'):\n",
    "        file_path = os.path.join(data_directory, filename)\n",
    "        \n",
    "        waitlist_df = pd.read_csv(file_path)\n",
    "        \n",
    "        # For each RECIPIENT_ID, prioritize non-NA DIAGNOSIS_CODE and FUNCTIONAL_CODE from all_transplants\n",
    "        all_transplants_filtered = all_transplants.dropna(subset=[Column.DIAGNOSIS_CODE.name, Column.FUNCTIONAL_CODE.name])\n",
    "        all_transplants_filtered = all_transplants_filtered.sort_values(by=Column.FUNCTIONAL_CODE.name, ascending=False)\n",
    "        all_transplants_filtered = all_transplants_filtered.drop_duplicates(subset=[Column.RECIPIENT_ID.name], keep='first')\n",
    "        \n",
    "        waitlist_df = waitlist_df.merge(\n",
    "            all_transplants_filtered[[Column.RECIPIENT_ID.name, Column.DIAGNOSIS_CODE.name, Column.FUNCTIONAL_STATUS_AT_REGISTRATION.name, Column.FUNCTIONAL_CODE.name]],\n",
    "            on=Column.RECIPIENT_ID.name,\n",
    "            how='left'\n",
    "        )\n",
    "        # Save the updated DataFrame back to the CSV file\n",
    "        waitlist_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transplants = all_transplants.dropna(subset=[Column.DONOR_ID.name, Column.ORGAN_TRANSPLANT_ID.name, Column.ORGAN_RECOVERY_DATE.name, Column.TRANSPLANT_DATE.name, Column.END_DATE.name]).sort_values(by=Column.TRANSPLANT_DATE.name)\n",
    "# all_transplants[[Column.DONOR_ID.name, Column.ORGAN_TRANSPLANT_ID.name, Column.ORGAN_RECOVERY_DATE.name, Column.TRANSPLANT_DATE.name, Column.END_DATE.name]].sort_values(by=Column.TRANSPLANT_DATE.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter data for the years 2002-2004\n",
    "filtered_transplants = all_transplants[\n",
    "    (all_transplants[Column.ORGAN_RECOVERY_DATE.name] >= '2020-01-01') & \n",
    "    (all_transplants[Column.ORGAN_RECOVERY_DATE.name] <= '2023-12-31')\n",
    "]\n",
    "\n",
    "# Extract year and month from ORGAN_RECOVERY_DATE\n",
    "filtered_transplants['Year'] = filtered_transplants[Column.ORGAN_RECOVERY_DATE.name].dt.year\n",
    "filtered_transplants['Month'] = filtered_transplants[Column.ORGAN_RECOVERY_DATE.name].dt.month\n",
    "\n",
    "# Plot distribution by year\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "filtered_transplants['Year'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Distribution of ORGAN_RECOVERY_DATE by Year (2002-2004)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Plot distribution by month\n",
    "plt.subplot(1, 2, 2)\n",
    "filtered_transplants['Month'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Distribution of ORGAN_RECOVERY_DATE by Month (2002-2004)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_rows_per_recovery_date = all_transplants.groupby(Column.ORGAN_RECOVERY_DATE.name).size().max()\n",
    "highest_rows_per_recovery_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.Timestamp('2020-04-03')\n",
    "available_organs = get_mininal_columns_available_organs(by_date=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_organs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "waitlist_members = get_mininal_columns_waitlist(by_date=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waitlist_members.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "date, [daily_organs, daily_waitlist_members] = get_next_day(date, allocated_ids =[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_waitlist_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAITLIST_FEATURES = [\n",
    "        Column.RECIPIENT_ID.name, \n",
    "        Column.INIT_MELD_PELD_LAB_SCORE.name, \n",
    "        Column.DAYS_ON_WAITLIST.name,\n",
    "        Column.RECIPIENT_BLOOD_TYPE.name,\n",
    "        Column.RECIPIENT_BLOOD_TYPE_AS_CODE.name,\n",
    "]\n",
    "sample_waitlist_members = waitlist_members[WAITLIST_FEATURES].head(5)\n",
    "sample_waitlist_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(current_date: pd.Timestamp, end_date: pd.Timestamp):\n",
    "    date = current_date\n",
    "    while date <= end_date:\n",
    "        date, [organs, waitlist_members] = get_next_day(date, allocated_ids=[], max_waitlist=1500)\n",
    "        \n",
    "        # Save organs and waitlist members to files\n",
    "        organs_filename = f\"data/{date.strftime('%Y-%m-%d')}_organs.csv\"\n",
    "        waitlist_filename = f\"data/{date.strftime('%Y-%m-%d')}_waitlist.csv\"\n",
    "        \n",
    "        organs.to_csv(organs_filename, index=False)\n",
    "        waitlist_members.to_csv(waitlist_filename, index=False)\n",
    "        \n",
    "        date += pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_dataset(pd.Timestamp('01-01-20'), pd.Timestamp('05-31-21')) #pd.Timestamp('12-31-20'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframes_for_dates(start_date: pd.Timestamp, end_date: pd.Timestamp) -> List[List[pd.DataFrame]]:\n",
    "    date = start_date\n",
    "    dataframes_list = []\n",
    "    \n",
    "    while date <= end_date:\n",
    "        organs, waitlist = read_from_file(date)\n",
    "        dataframes_list.append((organs, waitlist))\n",
    "        date += pd.Timedelta(days=1)\n",
    "    \n",
    "    return dataframes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = read_dataframes_for_dates(pd.Timestamp('01-01-20'), pd.Timestamp('01-3-20'))\n",
    "dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_shape, action_size, hidden_size=64):\n",
    "        super(DQN, self).__init__()\n",
    "        # Flatten the state shape to get the input size for the first layer\n",
    "        input_size = state_shape[0] * state_shape[1]\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, action_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "        \n",
    "    def push(self, state, action, reward, next_state, done, info):\n",
    "        self.memory.append((state, action, reward, next_state, done, info))\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        states, actions, rewards, next_states, dones, infos = zip(*batch)\n",
    "        return (np.array(states, dtype=np.float32),\n",
    "                np.array(actions, dtype=np.int64),\n",
    "                np.array(rewards, dtype=np.float32),\n",
    "                np.array(next_states, dtype=np.float32),\n",
    "                np.array(dones, dtype=np.bool_),\n",
    "                infos)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrganMatchingEnv:\n",
    "    def __init__(self, max_waitlist_members: int = 100, max_days: int = 3, start_date_month_bound: int = 1, end_date_month_bound: int = 3, is_test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_waitlist_members: The number of max people to consider on the waitlist (it is sorted by MELD and days on waitlist)                             \n",
    "            max_days: The horizon over which we measure performance or run the simulation.\n",
    "\n",
    "        We assume:\n",
    "        - Each day we have multiple donors and multiple recipients.\n",
    "        - Each step in the environment involves selecting a recipient for the **current donor**.\n",
    "          After all donors for that day are processed, we move to the next day.\n",
    "        \"\"\"\n",
    "        self.start_date_month_bound = start_date_month_bound\n",
    "        self.end_date_month_bound = end_date_month_bound\n",
    "        self.max_waitlist_members = max_waitlist_members\n",
    "        self.max_days = max_days\n",
    "        self.is_test = is_test\n",
    "\n",
    "        # These will be set at reset\n",
    "        self.reset()\n",
    "    \n",
    "    def _get_start_date(self):\n",
    "        return pd.Timestamp(f'2020-{random.randint(self.start_date_month_bound, self.end_date_month_bound):02d}-{random.randint(1, 28):02d}')\n",
    "\n",
    "    def reset(self):\n",
    "        self.total_days_allocated = -1\n",
    "        self.initial_date = self._get_start_date() if not self.is_test else pd.Timestamp('2020-11-1')\n",
    "        self.current_day_idx = self.initial_date\n",
    "        self.current_donor_idx = 0\n",
    "        self.donor_ids_allocated = set()\n",
    "        self.refetch_data(self.initial_date)\n",
    "        return self._get_state()\n",
    "    \n",
    "    def refetch_data(self, date: pd.Timestamp):\n",
    "        logging.info(f'Refetching data for date: {date}. Allocated donor IDs: {self.donor_ids_allocated}')\n",
    "        self.current_day_idx, data = get_next_day(date, allocated_ids=self.donor_ids_allocated, max_waitlist=self.max_waitlist_members)\n",
    "        self.available_donor_df = data[0]\n",
    "        self.waitlist_member_df = data[1]\n",
    "        # Check if there are any donors left to allocate\n",
    "        available_donors = self.available_donor_df[Column.DONOR_ID.name].tolist()\n",
    "        unallocated_donors = [i for i, donor_id in enumerate(available_donors) if donor_id not in self.donor_ids_allocated]\n",
    "        if len(unallocated_donors) == 0:\n",
    "            logging.info(f'WARNING: No unallocated donors available for date: {self.current_day_idx}')\n",
    "            self.refetch_data(self.current_day_idx + pd.Timedelta(days=1))\n",
    "        else:\n",
    "            self.current_donor_idx = unallocated_donors[0]\n",
    "        \n",
    "        if date < self.current_day_idx:\n",
    "            logging.info(f'Moving onto next day {self.current_day_idx} with donor index {self.current_donor_idx} for donor ID: {self._get_donor()}')\n",
    "        else: \n",
    "            logging.info(f'Staying on {self.current_day_idx} to keep allocating for donor idx {self.current_donor_idx} because we have the remaining donors: {self._get_remaining_donors()}')\n",
    "    \n",
    "    def _get_valid_actions_for_df(self, donor_id: int, organs: pd.DataFrame, waitlist: pd.DataFrame):\n",
    "        if donor_id > len(organs):\n",
    "            logging.info(f'ERROR: {donor_id} > length of organs {len(organs)} on day {self.current_day_idx}')\n",
    "        donor = organs.iloc[donor_id]\n",
    "        donor_blood_type = donor[Column.DONOR_BLOOD_TYPE.name]\n",
    "        valid_allocations = [i for i in range(len(waitlist)) if get_match_value(donor_blood_type=donor_blood_type, recipient_blood_type=waitlist.iloc[i][Column.RECIPIENT_BLOOD_TYPE.name]) >= 1.0]\n",
    "        return valid_allocations\n",
    "    \n",
    "    def _get_remaining_donors(self):\n",
    "        return self.available_donor_df[Column.DONOR_ID.name].tolist()\n",
    "\n",
    "    def get_valid_actions(self):\n",
    "        return self._get_valid_actions_for_df(self.current_donor_idx, self.available_donor_df, self.waitlist_member_df)\n",
    "\n",
    "    def _get_state(self):\n",
    "        self.refetch_data(self.current_day_idx)\n",
    "        encoded_array = np.array([\n",
    "            list(row) for row in zip(self.waitlist_member_df[Column.INIT_MELD_PELD_LAB_SCORE.name], \n",
    "                                    self.waitlist_member_df[Column.DAYS_ON_WAITLIST.name], \n",
    "                                    self.waitlist_member_df[Column.RECIPIENT_BLOOD_TYPE_AS_CODE.name],\n",
    "                                    self.waitlist_member_df[Column.DIAGNOSIS_CODE.name],\n",
    "                                    self.waitlist_member_df[Column.FUNCTIONAL_CODE.name])\n",
    "        ])\n",
    "        state = np.array(encoded_array, dtype=np.float32)\n",
    "        return state\n",
    "    \n",
    "    def _get_donor(self):\n",
    "        return int(self.available_donor_df.iloc[self.current_donor_idx][Column.DONOR_ID.name])\n",
    "    \n",
    "    def _get_chosen_recipient(self, action: int):\n",
    "        if action > len(self.waitlist_member_df):\n",
    "            return pd.Series.empty()\n",
    "        return self.waitlist_member_df.iloc[action]\n",
    "\n",
    "    def step(self, action: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            action: index corresponding to the chosen recipient in waitlist_member_df.\n",
    "                    This means action is in [0, max_waitlist_members_to_consider].\n",
    "        \n",
    "        Returns:\n",
    "            next_state: state after this allocation\n",
    "            reward: float, e.g. graft lifespan or related metric\n",
    "            done: bool, whether the episode ended\n",
    "            info: dict, extra info\n",
    "        \"\"\"\n",
    "        chosen_recipient = self._get_chosen_recipient(action)\n",
    "        self.total_days_allocated += 1\n",
    "        self.donor_ids_allocated.add(self._get_donor())\n",
    "        self.donor_ids_allocated.add(int(chosen_recipient[Column.DONOR_ID.name]))\n",
    "        reward = 0.0\n",
    "        if chosen_recipient.empty:\n",
    "            reward = -100\n",
    "        else:  \n",
    "            # It doesn't matter who they got the organ from. Just include the rewards of this person getting an organ.\n",
    "            if chosen_recipient[Column.GRAFT_LIFESPAN.name] is not None:\n",
    "                reward += float(chosen_recipient[Column.GRAFT_LIFESPAN.name])\n",
    "            if chosen_recipient[Column.GRAFT_LIFESPAN.name] is not None:\n",
    "                reward += float(chosen_recipient[Column.PATIENT_SURVIVAL_TIME.name])\n",
    "        chosen_donor = self._get_donor()\n",
    "        logging.info(f'''Chose recipient ID: {chosen_recipient[Column.RECIPIENT_ID.name]} for donor {chosen_donor} with : {reward}''')\n",
    "\n",
    "        reward = np.log10(reward) if reward > 0 else 0\n",
    "        done = (self.total_days_allocated >= self.max_days)\n",
    "        valid_allocations = []\n",
    "        invalid_allocations = []\n",
    "        if not done:\n",
    "            next_state = self._get_state()\n",
    "            next_actions = np.arange(self.max_waitlist_members)\n",
    "            valid_allocations = self.get_valid_actions()\n",
    "            invalid_allocations = [i for i in next_actions if i not in valid_allocations]\n",
    "        else:\n",
    "            next_state = np.zeros_like(self._get_state())\n",
    "\n",
    "        return next_state, reward, done, {'next_valid_allocations': valid_allocations, 'next_invalid_allocations': invalid_allocations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "env = OrganMatchingEnv()\n",
    "env.reset()\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    valid_actions = env.get_valid_actions()\n",
    "    next_state, reward, done, _ = env.step(random.choice(valid_actions))\n",
    "    total_reward += reward\n",
    "    print(f'Reward: {total_reward} and reached done? {done}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(lr: float, batch_size: int, waitlist_members: int, max_days: int, ep: int, rewards: bool = False):\n",
    "    return f\"{'rewards' if rewards else 'policy_net'}_lr_{lr}_bs_{batch_size}_ws_{waitlist_members}_ma_{max_days}_ep{ep if not rewards else ''}.{'csv' if rewards else 'pkl'}\"\n",
    "\n",
    "def plot_rewards(all_rewards, batch_size, max_waitlist_members, max_days):\n",
    "    window_size = 5  # Adjust the window size for smoothing\n",
    "    smoothed_rewards = np.convolve(all_rewards, np.ones(window_size) / window_size, mode='valid')\n",
    "    # Plot original and smoothed rewards\n",
    "    plt.plot(all_rewards, label='Original', alpha=0.4)\n",
    "    plt.plot(range(len(smoothed_rewards)), smoothed_rewards, label='Smoothed', color='red')\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(f\"Reward per Episode (batch_size={batch_size}, max_waitlist_members={max_waitlist_members}, max allocations={max_days})\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"bs_{batch_size}_ws_{max_waitlist_members}_ma_{max_days}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dqn(env: OrganMatchingEnv,\n",
    "             policy_net: DQN,\n",
    "             episodes: int = 10) -> float:\n",
    "    \"\"\"\n",
    "    Run inference using the trained policy_net on the given test environment.\n",
    "    Returns the average reward over the given number of test episodes.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    \n",
    "    # Set the policy_net to evaluation mode\n",
    "    policy_net.eval()\n",
    "\n",
    "    total_reward = 0.0\n",
    "    chosen_patients = pd.DataFrame()\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0.0\n",
    "\n",
    "        while not done:\n",
    "            # The available actions on this step\n",
    "            action_size = env.max_waitlist_members\n",
    "            actions = np.arange(action_size)\n",
    "            valid_allocations = env.get_valid_actions()\n",
    "            invalid_allocations = [i for i in actions if i not in valid_allocations]\n",
    "\n",
    "            # Choose action greedily based on Q-values\n",
    "            with torch.no_grad():\n",
    "                q_values = policy_net(torch.tensor([state], dtype=torch.float32, device=device).view(-1))\n",
    "                # Mask out invalid actions\n",
    "                q_values[invalid_allocations] = -1e9\n",
    "                action = q_values.argmax().item()\n",
    "                chosen_patients = pd.concat([chosen_patients, env.waitlist_member_df.iloc[[action]]], ignore_index=True)\n",
    "\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "\n",
    "        total_reward += episode_reward\n",
    "        print(f\"Test Episode {ep+1}/{episodes}, Current date: {env.current_day_idx}, Reward: {episode_reward:.2f}\")\n",
    "\n",
    "    avg_reward = total_reward / episodes\n",
    "    print(f\"Average Test Reward over {episodes} episodes: {avg_reward:.2f}\")\n",
    "    return avg_reward, chosen_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "def train_dqn(env: OrganMatchingEnv,\n",
    "              episodes: int = 100,\n",
    "              gamma: float=0.99,\n",
    "              epsilon_start: float = 1.0,\n",
    "              epsilon_end: float = 0.01,\n",
    "              epsilon_decay: int = 500,\n",
    "              lr: float = 1e-3,\n",
    "              batch_size: int = 128,\n",
    "              memory_capacity: int = 1000,\n",
    "              target_update: int = 200):\n",
    "    # Initialize replay memory\n",
    "    memory = ReplayMemory(memory_capacity)\n",
    "\n",
    "    state = env.reset()\n",
    "    state_size = state.shape\n",
    "    action_size = env.max_waitlist_members\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    policy_net = DQN(state_size, action_size).to(device)\n",
    "    target_net = DQN(state_size, action_size).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "    \n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
    "    epsilon = epsilon_start\n",
    "    steps_done = 0\n",
    "    all_rewards = []\n",
    "\n",
    "    for ep in tqdm(range(episodes), desc=\"Training Episodes\"):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0.0\n",
    "        \n",
    "        while not done:\n",
    "            steps_done += 1\n",
    "\n",
    "            # The actual available actions on this step is equal to the current day's recipients\n",
    "            actions = np.arange(action_size)\n",
    "            valid_allocations = env.get_valid_actions()\n",
    "            invalid_allocations = [i for i in actions if i not in valid_allocations]\n",
    "            \n",
    "            # Epsilon-greedy action selection\n",
    "            if random.random() < epsilon:\n",
    "                # Random action from the valid range of recipients\n",
    "                action = random.choice(valid_allocations)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    q_values = policy_net(torch.tensor([state], dtype=torch.float32, device=device).view(-1))\n",
    "                    # Mask out invalid actions by setting Q-values of invalid actions to a large negative number\n",
    "                    # print(q_values.shape)\n",
    "                    # print(invalid_allocations.shape)\n",
    "                    q_values[invalid_allocations] = -1e9\n",
    "                    action = q_values.argmax().item()\n",
    "\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            \n",
    "            memory.push(state, action, reward, next_state, done, info)\n",
    "            state = next_state\n",
    "\n",
    "            # Train if memory is sufficient\n",
    "            if len(memory) >= batch_size:\n",
    "                states_b, actions_b, rewards_b, next_states_b, dones_b, infos = memory.sample(batch_size)\n",
    "                \n",
    "                states_t = torch.tensor(states_b, dtype=torch.float32, device=device)\n",
    "                # size (batch size)\n",
    "                actions_t = torch.tensor(actions_b, device=device).unsqueeze(1)\n",
    "                rewards_t = torch.tensor(rewards_b, dtype=torch.float32, device=device)\n",
    "                next_states_t = torch.tensor(next_states_b, dtype=torch.float32, device=device)\n",
    "                dones_t = torch.tensor(dones_b, dtype=torch.bool, device=device)\n",
    "                \n",
    "                # Compute Q(s,a)\n",
    "                q_values = policy_net(states_t.view(batch_size, -1)).gather(1, actions_t)\n",
    "                \n",
    "                # Compute max Q(s',a') from target net\n",
    "                next_q_values_all = target_net(next_states_t.view(batch_size, -1))\n",
    "\n",
    "                # next_q_values_all is (batch_size, action_size)\n",
    "                for batch_idx, info_entry in enumerate(infos):\n",
    "                    invalid_allocations = info_entry['next_invalid_allocations']\n",
    "                    next_q_values_all[batch_idx, invalid_allocations] = -1e9\n",
    "\n",
    "                next_q_values = next_q_values_all.max(1)[0]\n",
    "                next_q_values[dones_t] = 0.0\n",
    "                \n",
    "                target = rewards_t + gamma * next_q_values\n",
    "                \n",
    "                loss = nn.MSELoss()(q_values.squeeze(), target)\n",
    "            \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Decay epsilon\n",
    "            epsilon = epsilon_end + (epsilon_start - epsilon_end) * np.exp(-steps_done / epsilon_decay)\n",
    "        \n",
    "        # Update target network\n",
    "        if ep % target_update == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "        all_rewards.append(episode_reward)\n",
    "        if ep > 50 and episode_reward >= (max(all_rewards) if len(all_rewards) > 0 else 0):    \n",
    "            # Save the policy net to a pickle file\n",
    "            with open(get_filename(lr, batch_size, env.max_waitlist_members, env.max_days, ep, rewards=False), 'wb') as f:\n",
    "                torch.save(policy_net.state_dict(), f)\n",
    "            # Save the rewards to a CSV file\n",
    "            rewards_df = pd.DataFrame(all_rewards, columns=['Reward'])\n",
    "            rewards_df.to_csv(get_filename(lr, batch_size, env.max_waitlist_members, env.max_days, ep, rewards=True), index=False)\n",
    "            plot_rewards(all_rewards, batch_size, env.max_waitlist_members, env.max_days)\n",
    "\n",
    "        print(f\"Episode {ep+1}/{episodes}, Reward: {episode_reward:.2f}, Date: {env.current_day_idx} Epsilon: {epsilon:.2f}\")\n",
    "    return policy_net, all_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_waitlist_members = 250\n",
    "max_days = 100\n",
    "episodes = 125\n",
    "env = OrganMatchingEnv(max_waitlist_members=max_waitlist_members, max_days=max_days)\n",
    "trained_policy, rewards = train_dqn(env,batch_size=128, episodes=episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_waitlist_members = 250\n",
    "# test_policy_net = DQN((max_waitlist_members, 5), max_waitlist_members)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# filename = \"policy_net_lr_0.001_bs_128_ws_250_ma_100_ep160.pkl\" \n",
    "\n",
    "# with open(filename, 'rb') as f:\n",
    "#     state_dict = torch.load(f, map_location=device)\n",
    "#     test_policy_net.load_state_dict(state_dict)\n",
    "\n",
    "# Move the model to the device and set to eval mode\n",
    "test_policy_net = trained_policy\n",
    "test_policy_net.to(device)\n",
    "test_policy_net.eval()\n",
    "test_env = OrganMatchingEnv(max_waitlist_members=max_waitlist_members, max_days=500, is_test=True)\n",
    "print(f\"Starting at {test_env.initial_date}\")\n",
    "average_test_reward, chosen_patients = test_dqn(test_env, test_policy_net, episodes=1)\n",
    "print(f\"Reward: {average_test_reward}\")\n",
    "chosen_patients\n",
    "\n",
    "1566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_to_baseline(current_date: pd.Timestamp, end_date: pd.Timestamp, max_allocations: int):\n",
    "    total_rewards = []\n",
    "    all_filtered_patients = pd.DataFrame()\n",
    "\n",
    "    date = current_date\n",
    "    allocated_ids = []\n",
    "    while date <= end_date and len(allocated_ids) < max_allocations:\n",
    "        # Get the next day's data\n",
    "        waitlist_members = get_mininal_columns_waitlist(by_date=date)     \n",
    "        filtered_waitlist_members = waitlist_members[waitlist_members[Column.TRANSPLANT_DATE.name] == date]\n",
    "        num_to_allocate = max_allocations - len(allocated_ids)\n",
    "        filtered_waitlist_members = filtered_waitlist_members.head(num_to_allocate) if len(filtered_waitlist_members) > num_to_allocate else filtered_waitlist_members\n",
    "        allocated_ids.extend(filtered_waitlist_members[Column.DONOR_ID.name].to_list())\n",
    "        \n",
    "        # For each row, add graft and patient survival time, take np.log10 and add to total_reward\n",
    "        for _, row in filtered_waitlist_members.iterrows():\n",
    "            graft_and_patient_survival = row[Column.GRAFT_LIFESPAN.name] + row[Column.PATIENT_SURVIVAL_TIME.name]\n",
    "            if graft_and_patient_survival > 0:\n",
    "                total_rewards.append(np.log10(graft_and_patient_survival))\n",
    "        \n",
    "        # Append the filtered waitlist members to the all_filtered_patients DataFrame\n",
    "        all_filtered_patients = pd.concat([all_filtered_patients, filtered_waitlist_members], ignore_index=True)\n",
    "        \n",
    "        date += pd.Timedelta(days=1)\n",
    "\n",
    "    return sum(total_rewards), all_filtered_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_along(column: Column, label: str, filename: str):\n",
    "    # Assuming 'chosen_patients' and 'baseline_patients' are DataFrames with a column 'INIT_MELD_PELD_LAB_SCORE'\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Create a side-by-side chart for chosen and baseline patients\n",
    "    chosen_scores = chosen_patients[column.name]\n",
    "    baseline_scores = baseline_patients[column.name]\n",
    "\n",
    "    # Define bins\n",
    "    bins = range(int(min(chosen_scores.min(), baseline_scores.min())), int(max(chosen_scores.max(), baseline_scores.max())) + 1)\n",
    "\n",
    "    # Plot side-by-side histogram\n",
    "    n, bins, patches = plt.hist([chosen_scores, baseline_scores], bins=bins, color=['skyblue', 'salmon'], edgecolor='black', stacked=False, label=['Chosen Patients', 'Baseline Patients'])\n",
    "\n",
    "    # Set background color for each histogram\n",
    "    for patch, color in zip(patches, ['skyblue', 'salmon']):\n",
    "        for rect in patch:\n",
    "            rect.set_facecolor(color)\n",
    "\n",
    "    plt.title(f'Side-by-Side Comparison of {label} for Chosen and Baseline Patients')\n",
    "    plt.xlabel(label)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.legend()  # Add legend\n",
    "    # Save the plot to a file with the same name as 'filename' but with a .png extension\n",
    "    plt.savefig(f\"{label}_{filename.rsplit('.', 1)[0]}.png\")\n",
    "\n",
    "baseline_rewards, baseline_patients = compare_to_baseline(pd.Timestamp('2020-07-01'), pd.Timestamp('2020-08-01'), max_allocations = 501)\n",
    "print(f\"Baseline rewards: {baseline_rewards}\")\n",
    "baseline_patients\n",
    "compare_along(Column.INIT_MELD_PELD_LAB_SCORE, 'MELD', filename)\n",
    "compare_along(Column.FUNCTIONAL_CODE, 'Functional Status', filename)\n",
    "compare_along(Column.RECIPIENT_AGE, 'Recipient Age', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize a dictionary to store rewards data\n",
    "rewards_data = {}\n",
    "\n",
    "# Iterate over files in the current directory\n",
    "for filename in os.listdir('.'):\n",
    "    if filename.startswith('rewards_') and filename.endswith('.csv'):\n",
    "        # Extract parameters from the filename\n",
    "        parts = filename.split('_')\n",
    "        lr = parts[2]  # Correct index for 'lr'\n",
    "        ws = parts[6]  # Correct index for 'ws'\n",
    "        ma = parts[8]  # Correct index for 'ma'\n",
    "        \n",
    "        # Create a label for the legend\n",
    "        label = f\"lr: {lr}, waitlist size: {ws}, max allocations: {ma}\"\n",
    "        \n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(filename)\n",
    "        \n",
    "        # Store the rewards data with the label\n",
    "        rewards_data[label] = df['Reward']\n",
    "\n",
    "# Plot the rewards data\n",
    "plt.figure(figsize=(12, 6))\n",
    "for label, rewards in rewards_data.items():\n",
    "    plt.plot(rewards, label=label)\n",
    "\n",
    "plt.title('Rewards Comparison Across Different Parameters')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(get_filename(0.001, 128, env.max_waitlist_members, env.max_days, 200, rewards=False), 'wb') as f:\n",
    "    torch.save(trained_policy.state_dict(), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs238",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
